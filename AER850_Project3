{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"k6URA11aCsuM"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSaJRKMyrzXE","executionInfo":{"status":"ok","timestamp":1764214962391,"user_tz":300,"elapsed":1246,"user":{"displayName":"Sam Hime","userId":"08308022158808709232"}},"outputId":"3b5d5fa1-0510-4541-b1b9-12f9edc47078"},"outputs":[{"output_type":"stream","name":"stdout","text":["Working directory set to: /content/gdrive/MyDrive/Colab Notebooks/project3_data\n","\n","GPU Status: NVIDIA A100-SXM4-40GB\n","Memory Allocated: 0.04 GB\n","--- Fixing data.yaml paths ---\n","Fixed YAML saved to: /content/gdrive/MyDrive/Colab Notebooks/project3_data/data_fixed.yaml\n","\n","--- Starting Step 3: Evaluation (Multi-Scale) ---\n","Predicting on: /content/gdrive/MyDrive/Colab Notebooks/project3_data/evaluation\n","Enabling Test-Time Augmentation (TTA) to catch both large and small objects...\n","\n","image 1/3 /content/gdrive/MyDrive/Colab Notebooks/project3_data/evaluation/ardmega.jpg: 1728x1920 1 Button, 16 Capacitors, 12 Connectors, 1 Diode, 2 Electrolytic Capacitors, 7 ICs, 2 Leds, 2 Padss, 25 Resistors, 30.7ms\n","image 2/3 /content/gdrive/MyDrive/Colab Notebooks/project3_data/evaluation/arduno.jpg: 1312x1920 2 Buttons, 20 Capacitors, 10 Connectors, 3 Diodes, 5 Electrolytic Capacitors, 7 ICs, 2 Inductors, 9 Leds, 2 Padss, 20 Resistors, 30.0ms\n","image 3/3 /content/gdrive/MyDrive/Colab Notebooks/project3_data/evaluation/rasppi.jpg: 1280x1920 39 Capacitors, 32 Connectors, 2 Diodes, 2 Electrolytic Capacitors, 11 ICs, 2 Inductors, 13 Leds, 5 Padss, 33 Resistors, 1 Switch, 29.9ms\n","Speed: 19.1ms preprocess, 30.2ms inference, 42.4ms postprocess per image at shape (1, 3, 1280, 1920)\n","Results saved to \u001b[1m/content/gdrive/MyDrive/Colab Notebooks/project3_data/runs/detect/pcb_model_Standard_1920_AntiOverfit/evaluation_results_TTA\u001b[0m\n","Evaluation Complete. Results saved to: /content/gdrive/MyDrive/Colab Notebooks/project3_data/runs/detect/pcb_model_Standard_1920_AntiOverfit/evaluation_results_TTA\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import subprocess\n","import sys\n","import yaml\n","import torch\n","\n","torch.cuda.empty_cache()\n","\n","try:\n","    import ultralytics\n","except ImportError:\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ultralytics\"])\n","\n","from ultralytics import YOLO\n","from google.colab import drive\n","\n","##### FOLDER CHANGE AND OTHER CONFIG STUFF\n","\n","MAIN_MODE = \"EVALUATION_ONLY\" # switch between diff modes because I dont want to train model again\n","\n","# CHECK THIS PATH\n","BASE_DIR_PATH = '/content/gdrive/MyDrive/Colab Notebooks/project3_data'\n","\n","# FOLDER NAME\n","TRAIN_PROJECT_NAME = 'pcb_model_Standard_1920_AntiOverfit'\n","TRAIN_RUNS_FOLDER = 'runs/detect'\n","\n","#### SETUP\n","\n","def setup_environment():\n","    if not os.path.exists('/content/gdrive/MyDrive'):\n","        drive.mount('/content/gdrive')\n","\n","    if not os.path.exists(BASE_DIR_PATH):\n","        print(f\"CRITICAL ERROR: Directory {BASE_DIR_PATH} not found.\")\n","        return None, None\n","    else:\n","        print(f\"Working directory set to: {BASE_DIR_PATH}\")\n","\n","    # Print GPU Info\n","    if torch.cuda.is_available():\n","        print(f\"\\nGPU Status: {torch.cuda.get_device_name(0)}\")\n","        print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n","    else:\n","        print(\"WARNING: No GPU detected. Training will be extremely slow.\")\n","\n","    yaml_path = os.path.join(BASE_DIR_PATH, 'data.yaml')\n","    fixed_yaml_path = os.path.join(BASE_DIR_PATH, 'data_fixed.yaml')\n","\n","    if not os.path.exists(yaml_path):\n","        print(f\"ERROR: data.yaml not found at {yaml_path}\")\n","        return BASE_DIR_PATH, None\n","\n","    print(f\"--- Fixing data.yaml paths ---\")\n","    with open(yaml_path, 'r') as f:\n","        config = yaml.safe_load(f)\n","\n","    config['path'] = BASE_DIR_PATH\n","    config['train'] = 'train/images'\n","    config['val'] = 'valid/images'\n","    config['test'] = 'test/images'\n","\n","    with open(fixed_yaml_path, 'w') as f:\n","        yaml.dump(config, f)\n","\n","    print(f\"Fixed YAML saved to: {fixed_yaml_path}\")\n","    return BASE_DIR_PATH, fixed_yaml_path\n","\n","def load_last_trained_model(base_dir):\n","    model_path = os.path.join(base_dir, TRAIN_RUNS_FOLDER, TRAIN_PROJECT_NAME, 'weights', 'best.pt')\n","    if not os.path.exists(model_path):\n","        return None, None\n","    model = YOLO(model_path)\n","    run_folder = os.path.dirname(os.path.dirname(model_path))\n","    return model, run_folder\n","\n","###################################################\n","# PART 1: OBJECT MAKSING\n","#############################################\n","def step1_object_masking(base_dir):\n","    print(\"\\n--- Starting Step 1: Object Masking ---\")\n","    img_path = os.path.join(base_dir, 'motherboard_image.JPEG')\n","    if not os.path.exists(img_path):\n","        img_path = os.path.join(base_dir, 'motherboard_image.jpg')\n","\n","    if not os.path.exists(img_path):\n","        print(f\"Error: Image not found at {img_path}\")\n","        return\n","\n","    # Process Images\n","    img = cv2.imread(img_path)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    blur = cv2.GaussianBlur(gray, (9, 9), 0)\n","    edges = cv2.Canny(blur, 30, 150)\n","\n","    kernel = np.ones((5, 5), np.uint8)\n","    dilated = cv2.dilate(edges, kernel, iterations=4)\n","    kernel_close = np.ones((25, 25), np.uint8)\n","    closed = cv2.morphologyEx(dilated, cv2.MORPH_CLOSE, kernel_close)\n","\n","    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    if contours:\n","        largest_contour = max(contours, key=cv2.contourArea)\n","        final_mask = np.zeros_like(gray)\n","        cv2.drawContours(final_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n","        result = cv2.bitwise_and(img, img, mask=final_mask)\n","        result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n","\n","        # --- DISPLAY & SAVE 1: ORIGINAL ---\n","        plt.figure(figsize=(6, 6))\n","        plt.imshow(img_rgb)\n","        plt.title(\"1. Original Image\")\n","        plt.axis('off')\n","        plt.show()\n","\n","        # --- DISPLAY & SAVE 2: GRAYSCALE ---\n","        plt.figure(figsize=(6, 6))\n","        plt.imshow(gray, cmap='gray')\n","        plt.title(\"Grayscale Image\")\n","        plt.axis('off')\n","        plt.show()\n","\n","        # --- DISPLAY & SAVE 3: MASK ---\n","        plt.figure(figsize=(6, 6))\n","        plt.imshow(final_mask, cmap='gray')\n","        plt.title(\"3. Binary Mask\")\n","        plt.axis('off')\n","        plt.show()\n","\n","        # --- DISPLAY & SAVE 4: EXTRACTED ---\n","        plt.figure(figsize=(6, 6))\n","        plt.imshow(result_rgb)\n","        plt.title(\"4. Final Extracted Image\")\n","        plt.axis('off')\n","        plt.show()\n","\n","        # Save separate files for your report\n","        cv2.imwrite(os.path.join(base_dir, 'report_step1_original.jpg'), img)\n","        cv2.imwrite(os.path.join(base_dir, 'report_step2_grayscale.jpg'), gray)\n","        cv2.imwrite(os.path.join(base_dir, 'report_step3_mask.jpg'), final_mask)\n","        cv2.imwrite(os.path.join(base_dir, 'report_step4_extracted.jpg'), result)\n","\n","        print(f\"Images saved individually to {base_dir} (look for 'report_stepX...')\")\n","\n","###################################################\n","# PART 2: YOLOv11 TRAINING\n","#############################################\n","\n","\n","def step2_yolo_training(base_dir, yaml_path):\n","    print(\"\\n--- Starting Step 2: YOLOv11 Training (Anti-Overfit) ---\")\n","    print(f\"Saving to folder: {TRAIN_PROJECT_NAME}\")\n","\n","    model = YOLO('yolo11n.pt')\n","\n","    # --- CONFIGURATION ---\n","    EPOCHS = 150\n","    IMG_SIZE = 1920\n","    BATCH_SIZE = 2\n","    WORKERS = 8\n","\n","    PROJECT_PATH = os.path.join(base_dir, TRAIN_RUNS_FOLDER)\n","    NAME = TRAIN_PROJECT_NAME\n","\n","    results = model.train(\n","        data=yaml_path,\n","        epochs=EPOCHS,\n","        imgsz=IMG_SIZE,\n","        batch=BATCH_SIZE,\n","        workers=WORKERS,\n","        project=PROJECT_PATH,\n","        name=NAME,\n","        exist_ok=True,\n","        plots=True,\n","        cache=False,\n","        amp=True,\n","        patience=15,\n","        dropout=0.1,\n","        cos_lr=True,\n","    )\n","\n","    print(\"Training Complete.\")\n","    final_run_path = os.path.join(PROJECT_PATH, NAME)\n","    return model, final_run_path\n","\n","###################################################\n","# PART 3: EVALUATION\n","#############################################\n","def step3_evaluation(model, base_dir, save_dir):\n","    print(\"\\n--- Starting Step 3: Evaluation (Multi-Scale) ---\")\n","\n","    eval_folder = os.path.join(base_dir, 'evaluation')\n","    if not os.path.exists(eval_folder):\n","        eval_folder = os.path.join(base_dir, 'test/images')\n","\n","    if not os.path.exists(eval_folder):\n","        print(f\"ERROR: Evaluation folder not found.\")\n","        return\n","\n","    print(f\"Predicting on: {eval_folder}\")\n","    print(\"Enabling Test-Time Augmentation (TTA) to catch both large and small objects...\")\n","\n","    model.predict(\n","        source=eval_folder,\n","        imgsz=1920,\n","        conf=0.15,\n","        iou=0.6,\n","        save=True,\n","        project=save_dir,\n","        name='evaluation_results_TTA',\n","        exist_ok=True,\n","        line_width=1,\n","        show_labels=True,\n","        augment=True\n","    )\n","    print(f\"Evaluation Complete. Results saved to: {save_dir}/evaluation_results_TTA\")\n","\n","# ==========================================\n","# MAIN EXECUTION\n","# ==========================================\n","if __name__ == \"__main__\":\n","    base_directory, fixed_yaml = setup_environment()\n","\n","    if base_directory and fixed_yaml:\n","        if MAIN_MODE == \"FULL_RUN\":\n","            step1_object_masking(base_directory)\n","            trained_model, run_path = step2_yolo_training(base_directory, fixed_yaml)\n","            if trained_model:\n","                step3_evaluation(trained_model, base_directory, run_path)\n","\n","        elif MAIN_MODE == \"EVALUATION_ONLY\":\n","            trained_model, run_path = load_last_trained_model(base_directory)\n","            if trained_model:\n","                step3_evaluation(trained_model, base_directory, run_path)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[],"authorship_tag":"ABX9TyOswFjj00W5YrsPYDaDmfJi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}